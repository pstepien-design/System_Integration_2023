From here:
https://www.proxiesapi.com/blog/how-to-scrape-wikipedia-using-python-scrapy.html.php

> scrapy startproject wikicrawler

> cd wikicrawler

> scrapy genspider WikiPageSpider https://en.wikipedia.org/wiki/List_of_common_misconceptions

Update the file /wikicrawler/wikicrawler/spiders/WikiPageSpider.py with the following code:

    import scrapy
    from scrapy.linkextractors import LinkExtractor
    from scrapy.spiders import CrawlSpider, Rule
    
    class WikipageSpider(CrawlSpider):
        name = 'WikiPageSpider'
        allowed_domains = ['en.wikipedia.org']
        start_urls = ['https://en.wikipedia.org/wiki/List_of_common_misconceptions']
    
        rules = (
            Rule(LinkExtractor(allow=r'/wiki/'), callback='parse_item', follow=True),
        )
    
        def parse_item(self, response):
            yield {
                'url': response.url,
                'title': response.css('h1::text').get(),
                'content': response.css('p::text').getall()
            }

Run spider and output content:
> scrapy crawl WikiPageSpider -o output.json

Alternatively interact from shell:
> scrapy shell https://en.wikipedia.org/wiki/List_of_common_misconceptions

To see response:
> response 

To get the title:
> response.css('h1').get()

To get the text content add ::text at the end of the selector:
> response.css('h1 > span ::text').get()